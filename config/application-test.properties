server.port=10335
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver
spring.jpa.database=MYSQL
spring.datasource.url=jdbc:mysql://localhost:3306/ddxf_medata?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull&serverTimezone=Asia/Shanghai

spring.datasource.username=root
spring.datasource.password=3/<N1Bwu</JK

spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
spring.datasource.maxWait=60000
spring.datasource.timeBetweenEvictionRunsMillis=60000
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
spring.datasource.poolPreparedStatements=false
spring.datasource.filters=config,stat
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000;config.decrpt=true;
spring.datasource.logSlowSql=true


###############blockchain##########################
service.restfulUrl=http://47.103.79.156:29830

###############mybatis ##########################
mybatis.config-location=classpath:mybatis-config.xml
mybatis.mapper-locations=classpath:/mapper/*Mapper.xml
mybatis.type-aliases-package=com.ontology.dao


contract.hash.sourcing=ad6501f33a3c65836cb9eb2531606641f86586df
contract.hash.dtoken=9ae36a2ee515645e75a60ce945f0828538b4e56b
contract.hash.medata=a79657801d048c08cfb211ac1b1bd8224e1cc44c


#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=0.0.0.0:9092

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=group-ddxf-insert

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
#spring.kafka.consumer.auto-commit-interval=1S

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

#设置手动提交offset
spring.kafka.listener.ack-mode=manual_immediate
spring.kafka.listener.concurrency=6
spring.kafka.consumer.max-poll-records=5

# Elasticsearch
elasticSearch.host=es-cn-v641arye7000tdmc8.elasticsearch.aliyuncs.com
elasticSearch.port=9200
elasticSearch.client.connectNum=10
elasticSearch.client.connectPerRoute=50
elasticSearch.username=elastic
elasticSearch.password=HMCXts6MTdPvE8UN