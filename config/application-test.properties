server.port=10335
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver
spring.jpa.database=MYSQL
spring.datasource.url=jdbc:mysql://localhost:3306/ddxf_medata?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull&serverTimezone=Asia/Shanghai

spring.datasource.username=root
spring.datasource.password=

spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
spring.datasource.maxWait=60000
spring.datasource.timeBetweenEvictionRunsMillis=60000
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
spring.datasource.poolPreparedStatements=false
spring.datasource.filters=config,stat
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000;config.decrpt=true;
spring.datasource.logSlowSql=true


###############Database Info ##########################
service.restfulUrl=http://47.103.79.156:29830

###############mybatis ##########################
mybatis.config-location=classpath:mybatis-config.xml
mybatis.mapper-locations=classpath:/mapper/*Mapper.xml
mybatis.type-aliases-package=com.ontology.dao


contract.hash.sourcing=ad6501f33a3c65836cb9eb2531606641f86586df
contract.hash.dtoken=9ae36a2ee515645e75a60ce945f0828538b4e56b
contract.hash.medata=cc65c036d49c3c56005c780987a0c93ea89a1af4


#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=0.0.0.0:9092

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=group-ddxf-insert

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
#spring.kafka.consumer.auto-commit-interval=1S

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

#设置手动提交offset
spring.kafka.listener.ack-mode=manual_immediate
spring.kafka.listener.concurrency=6
spring.kafka.consumer.max-poll-records=5

# Elasticsearch
elasticsearch.ip=0.0.0.0
elasticsearch.port=9300
elasticsearch.pool=5
elasticsearch.cluster.name=my-application
elasticsearch.sniff=false